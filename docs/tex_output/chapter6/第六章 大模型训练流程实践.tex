% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{\textbf{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\section{第六章
大模型训练流程实践}\label{ux7b2cux516dux7ae0-ux5927ux6a21ux578bux8badux7ec3ux6d41ux7a0bux5b9eux8df5}

\subsection{6.1 模型预训练}\label{ux6a21ux578bux9884ux8badux7ec3}

在上一章，我们逐步拆解了 LLM 的模型结构及训练过程，从零手写实现了 LLaMA
模型结构及 Pretrain、SFT 全流程，更深入地理解了 LLM
的模型原理及训练细节。但是，在实际应用中，手写实现的 LLM
训练存在以下问题：

\begin{itemize}
\tightlist
\item
  手写实现 LLM 结构工作量大，难以实时跟进最新模型的结构创新；
\item
  从零实现的 LLM 训练无法较好地实现多卡分布式训练，训练效率较低；
\item
  和现有预训练 LLM 不兼容，无法使用预训练好的模型参数
\end{itemize}

因此，在本章中，我们将介绍目前 LLM 领域的主流训练框架
Transformers，并结合分布式框架 deepspeed、高效微调框架 peft
等主流框架，实践使用 transformers 进行模型 Pretrain、SFT
全流程，更好地对接业界的主流 LLM 技术方案。

\subsubsection{6.1.1 框架介绍}\label{ux6846ux67b6ux4ecbux7ecd}

Transformers 是由 Hugging Face 开发的 NLP 框架，通过模块化设计实现了对
BERT、GPT、LLaMA、T5、ViT 等上百种主流模型架构的统一支持。通过使用
Transformers，开发者无需重复实现基础网络结构，通过 AutoModel
类即可一键加载任意预训练，图6.1 为 Hugging Face Transformers 课程首页：

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/1-1.png" alt="alt text" width="90%" />
<p>图6.1 Hugging Face Transformers</p>
\end{verbatim}

同时，框架内置的 Trainer 类封装了分布式训练的核心逻辑，支持 PyTorch 原生
DDP、DeepSpeed、Megatron-LM
等多种分布式训练策略。通过简单配置训练参数，即可实现数据并行、模型并行、流水线并行的混合并行训练，在
8 卡 A100 集群上可轻松支持百亿参数模型的高效训练。配合 SavingPolicy 和
LoggingCallback 等组件，实现了训练过程的自动化管理。其还支持与
Deepspeed、peft、wandb、Swanlab
等框架进行集成，直接通过参数设置即可无缝对接，从而快速、高效实现 LLM
训练。

对 LLM 时代的 NLP 研究者更为重要的是，HuggingFace 基于 Transformers
框架搭建了其庞大的 AI
社区，开放了数亿个预训练模型参数、25万+不同类型数据集，通过
Transformers、Dataset、Evaluate
等多个框架实现对预训练模型、数据集及评估函数的集成，从而帮助开发者可以便捷地使用任一预训练模型，在开源模型及数据集的基础上便捷地实现个人模型的开发与应用。

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/1-2.png" alt="alt text" width="90%" />
<p>图6.2 Hugging Face Transformers 模型社区</p>
\end{verbatim}

在 LLM
时代，模型结构的调整和重新预训练越来越少，开发者更多的业务应用在于使用预训练好的
LLM 进行 Post Train 和
SFT，来支持自己的下游业务应用。且由于预训练模型体量大，便捷集成
deepspeed 等分布式训练框架逐渐成为 LLM 时代 NLP
模型训练的必备技能。因此，Transformers 已逐步成为学界、业界 NLP
技术的主流框架，不管是企业业务开发还是科研研究，都逐渐首选 Transformers
进行模型实现。同时，新发布的开源 LLM 如 DeepSeek、Qwen 也都会第一时间在
Transformers 社区开放其预训练权重与模型调用 Demo。通过使用 Transformers
框架，可以高效、便捷地完成 LLM
训练及开发，实现工业级的产出交付。接下来，我们就会以 Transformers
框架为基础，介绍如何通过 Transformers 框架实现 LLM 的 Pretrain 及 SFT。

\subsubsection{6.1.2 初始化 LLM}\label{ux521dux59cbux5316-llm}

我们可以使用 transformers 的 AutoModel
类来直接初始化已经实现好的模型。对于任意预训练模型，其参数中都包含有模型的配置信息。如果是想要从头训练一个
LLM，可以使用一个已有的模型架构来直接初始化。这里，我们以
\href{https://huggingface.co/Qwen/Qwen2.5-1.5B/tree/main}{Qwen-2.5-1.5B}的模型架构为例：

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/1-3.png" alt="alt text" width="90%" />
<p>图6.3 Qwen-2.5-1.5B</p>
\end{verbatim}

该界面即为 HuggingFace 社区中的 Qwen-2.5-1.5B 模型参数，其中的
\texttt{config.json}
文件即是模型的配置信息，包括了模型的架构、隐藏层大小、模型层数等，如图6.4所示：

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/1-4.png" alt="alt text" width="90%" />
<p>图6.4 Qwen-2.5-1.5B config.json 文件</p>
\end{verbatim}

我们可以沿用该模型的配置信息，初始化一个 Qwen-2.5-1.5B
模型来进行训练，也可以在该配置信息的基础上进行更改，如修改隐藏层大小、注意力头数等，来定制一个模型结构。HuggingFace
提供了 Python 工具来便捷下载想使用的模型参数：

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ os}
\CommentTok{\# 设置环境变量，此处使用 HuggingFace 镜像网站}
\NormalTok{os.environ[}\StringTok{\textquotesingle{}HF\_ENDPOINT\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{\textquotesingle{}https://hf{-}mirror.com\textquotesingle{}}
\CommentTok{\# 下载模型}
\NormalTok{os.system(}\StringTok{\textquotesingle{}huggingface{-}cli download {-}{-}resume{-}download Qwen/Qwen2.5{-}1.5B {-}{-}local{-}dir your\_local\_dir\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

如图6.5，此处的
``Qwen/Qwen2.5-1.5B''即为要下载模型的标识符，对于其他模型，可以直接复制
HuggingFace 上的模型名即可：

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/1-5.png" alt="alt text" width="90%" />
<p>图6.5 模型下载标识</p>
\end{verbatim}

下载完成后，可以使用 AutoConfig 类直接加载下载好的配置文件：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 加载定义好的模型参数{-}此处以 Qwen{-}2.5{-}1.5B 为例}
\CommentTok{\# 使用 transforemrs 的 Config 类进行加载}
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ AutoConfig}

\CommentTok{\# 下载参数的本地路径}
\NormalTok{model\_path }\OperatorTok{=} \StringTok{"qwen{-}1.5b"}
\NormalTok{config }\OperatorTok{=}\NormalTok{ AutoConfig.from\_pretrained(model\_name\_or\_path)}
\end{Highlighting}
\end{Shaded}

也可以对配置文件进行自定义，然后以同样的方式加载即可。可以使用 AutoModel
类基于加载好的配置对象生成对应的模型：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 使用该配置生成一个定义好的模型}
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ AutoModelForCausalLM}

\NormalTok{model }\OperatorTok{=}\NormalTok{ AutoModelForCausalLM.from\_config(config,trust\_remote\_code}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

由于 LLM 一般都是 CausalLM 架构，此处使用了 AutoModelForCausalLM
类进行加载。如果是用于分类任务训练，可使用
AutoModelForSequenceClassification 类来加载。查看该
model，图6.6可以看到其架构和定义的配置文件相同：

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/1-6.png" alt="alt text" width="70%" />
<p>图6.6 模型结构输出结果</p>
\end{verbatim}

该 model 就是一个从零初始化的 Qwen-2.5-1.5B
模型了。一般情况下，我们很少从零初始化 LLM
进行预训练，较多的做法是加载一个预训练好的 LLM
权重，在自己的语料上进行后训练。这里，我们也介绍如何从下载好的模型参数中初始化一个预训练好的模型。

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ AutoModelForCausalLM}

\NormalTok{model }\OperatorTok{=}\NormalTok{ AutoModelForCausalLM.from\_pretrained(model\_name\_or\_path,trust\_remote\_code}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

类似的，直接使用 from\_pretrained 方法加载即可，此处的
model\_name\_or\_path 即为下载好的参数的本地路径。

我们还需要初始化一个 tokenizer。此处，我们直接使用 Qwen-2.5-1.5B 对应的
tokenzier 参数即可：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 加载一个预训练好的 tokenizer}
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ AutoTokenizer}

\NormalTok{tokenizer }\OperatorTok{=}\NormalTok{ AutoTokenizer.from\_pretrained(model\_name\_or\_path)}
\end{Highlighting}
\end{Shaded}

加载好的 tokenizer 即可直接使用，对任意文本进行分词处理。

\subsubsection{6.1.3
预训练数据处理}\label{ux9884ux8badux7ec3ux6570ux636eux5904ux7406}

与第五章类似，我们使用出门问问序列猴子开源数据集作为预训练数据集，可以用与第五章一致的方式进行数据集的下载和解压。HuggingFace
的 datasets 库是和 transformers
框架配套的、用于数据下载和处理的第三方库。我们可以直接使用 datasets 的
load\_dataset 函数来加载预训练数据：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 加载预训练数据}
\ImportTok{from}\NormalTok{ datasets }\ImportTok{import}\NormalTok{ load\_dataset}

\NormalTok{ds }\OperatorTok{=}\NormalTok{ load\_dataset(}\StringTok{\textquotesingle{}json\textquotesingle{}}\NormalTok{, data\_files}\OperatorTok{=}\StringTok{\textquotesingle{}/mobvoi\_seq\_monkey\_general\_open\_corpus.jsonl\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

注意，由于数据集较大，加载可能会出现时间较长或内存不够的情况，建议前期测试时将预训练数据集拆分一部分出来进行测试。加载出来的
ds 是一个 DatasetDict 对象，加载的数据会默认保存在 \texttt{train}
键对应的值中，可以通过以下代码查看：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ds[}\StringTok{"train"}\NormalTok{][}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/1-7.png" alt="alt text" width="100%" />
<p>图6.7 数据集展示</p>
\end{verbatim}

可以通过 feature
属性查看数据集的特征（也就是列），这里需要保存一下数据集的列名，因为后续数据处理时，再将文本
tokenize 之后，需要移除原先的文本：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 查看特征}
\NormalTok{column\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(ds[}\StringTok{"train"}\NormalTok{].features)}
\CommentTok{\# columnes\_name:["text"]}
\end{Highlighting}
\end{Shaded}

接着使用加载好的 tokenizer 对数据集进行处理，此处使用 map
函数来进行批量处理：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 对数据集进行 tokenize}
\KeywordTok{def}\NormalTok{ tokenize\_function(examples):}
    \CommentTok{\# 使用预先加载的 tokenizer 进行分词}
\NormalTok{    output }\OperatorTok{=}\NormalTok{ tokenizer([item }\ControlFlowTok{for}\NormalTok{ item }\KeywordTok{in}\NormalTok{ examples[}\StringTok{"text"}\NormalTok{]])}
    \ControlFlowTok{return}\NormalTok{ output}

\CommentTok{\# 批量处理}
\NormalTok{tokenized\_datasets }\OperatorTok{=}\NormalTok{ ds.}\BuiltInTok{map}\NormalTok{(}
\NormalTok{    tokenize\_function,}
\NormalTok{    batched}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{    num\_proc}\OperatorTok{=}\DecValTok{10}\NormalTok{,}
\NormalTok{    remove\_columns}\OperatorTok{=}\NormalTok{column\_names,}
\NormalTok{    load\_from\_cache\_file}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{    desc}\OperatorTok{=}\StringTok{"Running tokenizer on dataset"}\NormalTok{,}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

处理完成后的数据集会包括'input\_ids', 'attention\_mask'两列，分别是文本
tokenize 之后的数值序列和注意力掩码（标识是否 padding）。map 方法会通过
remove\_columns 参数将原先的`text'移除，训练中不再使用。

由于预训练一般为 CLM
任务，一次性学习多个样本的序列语义不影响模型性能，且训练数据量大、训练时间长，对训练效率要求比较高。在预训练过程中，一般会把多个文本段拼接在一起，处理成统一长度的文本块，再对每个文本块进行训练。在这里，我们实现一个拼接函数将文本块拼接到
2048个 token 长度，再通过 map 方法来进行批量处理：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 预训练一般将文本拼接成固定长度的文本段}
\ImportTok{from}\NormalTok{ itertools }\ImportTok{import}\NormalTok{ chain}

\CommentTok{\# 这里我们取块长为 2048}
\NormalTok{block\_size }\OperatorTok{=} \DecValTok{2048}

\KeywordTok{def}\NormalTok{ group\_texts(examples):}
    \CommentTok{\# 将文本段拼接起来}
\NormalTok{    concatenated\_examples }\OperatorTok{=}\NormalTok{ \{k: }\BuiltInTok{list}\NormalTok{(chain(}\OperatorTok{*}\NormalTok{examples[k])) }\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ examples.keys()\}}
    \CommentTok{\# 计算拼起来的整体长度}
\NormalTok{    total\_length }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(concatenated\_examples[}\BuiltInTok{list}\NormalTok{(examples.keys())[}\DecValTok{0}\NormalTok{]])}
    \CommentTok{\# 如果长度太长，进行分块}
    \ControlFlowTok{if}\NormalTok{ total\_length }\OperatorTok{\textgreater{}=}\NormalTok{ block\_size:}
\NormalTok{        total\_length }\OperatorTok{=}\NormalTok{ (total\_length }\OperatorTok{//}\NormalTok{ block\_size) }\OperatorTok{*}\NormalTok{ block\_size}
    \CommentTok{\# 按 block\_size 进行切分}
\NormalTok{    result }\OperatorTok{=}\NormalTok{ \{}
\NormalTok{        k: [t[i : i }\OperatorTok{+}\NormalTok{ block\_size] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, total\_length, block\_size)]}
        \ControlFlowTok{for}\NormalTok{ k, t }\KeywordTok{in}\NormalTok{ concatenated\_examples.items()}
\NormalTok{    \}}
    \CommentTok{\# CLM 任务，labels 和 input 是相同的}
\NormalTok{    result[}\StringTok{"labels"}\NormalTok{] }\OperatorTok{=}\NormalTok{ result[}\StringTok{"input\_ids"}\NormalTok{].copy()}
    \ControlFlowTok{return}\NormalTok{ result}

\CommentTok{\# 批量处理}
\NormalTok{lm\_datasets }\OperatorTok{=}\NormalTok{ tokenized\_datasets.}\BuiltInTok{map}\NormalTok{(}
\NormalTok{    group\_texts,}
\NormalTok{    batched}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{    num\_proc}\OperatorTok{=}\DecValTok{10}\NormalTok{,}
\NormalTok{    load\_from\_cache\_file}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{    desc}\OperatorTok{=}\SpecialStringTok{f"Grouping texts in chunks of }\SpecialCharTok{\{}\NormalTok{block\_size}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
\NormalTok{    batch\_size }\OperatorTok{=} \DecValTok{40000}\NormalTok{,}
\NormalTok{)}
\NormalTok{train\_dataset }\OperatorTok{=}\NormalTok{ lm\_datasets[}\StringTok{"train"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

处理得到的 train\_dataset 就是一个可直接用于 CLM Pretrain
的预训练数据集了，其每个样本长度为 2048个 token。

\subsubsection{6.1.4 使用 Trainer
进行训练}\label{ux4f7fux7528-trainer-ux8fdbux884cux8badux7ec3}

接下来，我们使用 transformers 提供的 Trainer 类进行训练。Trainer
封装了模型的训练逻辑，且做了较好的效率优化、可视化等工作，可以高效、便捷地完成
LLM 的训练。

首先我们需要配置训练的超参数，使用 TrainingArguments
类来实例化一个参数对象：

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ TrainingArguments}
\CommentTok{\# 配置训练参数}

\NormalTok{training\_args }\OperatorTok{=}\NormalTok{ TrainingArguments(}
\NormalTok{    output\_dir}\OperatorTok{=}\StringTok{"output"}\NormalTok{,}\CommentTok{\# 训练参数输出路径}
\NormalTok{    per\_device\_train\_batch\_size}\OperatorTok{=}\DecValTok{4}\NormalTok{,}\CommentTok{\# 训练的 batch\_size}
\NormalTok{    gradient\_accumulation\_steps}\OperatorTok{=}\DecValTok{4}\NormalTok{,}\CommentTok{\# 梯度累计步数，实际 bs = 设置的 bs * 累计步数}
\NormalTok{    logging\_steps}\OperatorTok{=}\DecValTok{10}\NormalTok{,}\CommentTok{\# 打印 loss 的步数间隔}
\NormalTok{    num\_train\_epochs}\OperatorTok{=}\DecValTok{1}\NormalTok{,}\CommentTok{\# 训练的 epoch 数}
\NormalTok{    save\_steps}\OperatorTok{=}\DecValTok{100}\NormalTok{, }\CommentTok{\# 保存模型参数的步数间隔}
\NormalTok{    learning\_rate}\OperatorTok{=}\FloatTok{1e{-}4}\NormalTok{,}\CommentTok{\# 学习率}
\NormalTok{    gradient\_checkpointing}\OperatorTok{=}\VariableTok{True}\CommentTok{\# 开启梯度检查点}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

然后基于初始化的 model、tokenzier 和
training\_args，并传入处理好的训练数据集，实例化一个 trainer 对象：

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ Trainer, default\_data\_collator}
\ImportTok{from}\NormalTok{ torchdata.datapipes.}\BuiltInTok{iter} \ImportTok{import}\NormalTok{ IterableWrapper}

\CommentTok{\# 训练器}
\NormalTok{trainer }\OperatorTok{=}\NormalTok{ Trainer(}
\NormalTok{    model}\OperatorTok{=}\NormalTok{model,}
\NormalTok{    args}\OperatorTok{=}\NormalTok{training\_args,}
\NormalTok{    train\_dataset}\OperatorTok{=}\NormalTok{ IterableWrapper(train\_dataset),}
\NormalTok{    eval\_dataset}\OperatorTok{=} \VariableTok{None}\NormalTok{,}
\NormalTok{    tokenizer}\OperatorTok{=}\NormalTok{tokenizer,}
    \CommentTok{\# 默认为 MLM 的 collator，使用 CLM 的 collater}
\NormalTok{    data\_collator}\OperatorTok{=}\NormalTok{default\_data\_collator}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

再使用 train 方法，即会按照配置好的训练超参进行训练和保存：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trainer.train()}
\end{Highlighting}
\end{Shaded}

\begin{quote}
注：上述代码存放于 \texttt{./code/pretrian.ipynb} 文件中。
\end{quote}

\subsubsection{6.1.5 使用 DeepSpeed
实现分布式训练}\label{ux4f7fux7528-deepspeed-ux5b9eux73b0ux5206ux5e03ux5f0fux8badux7ec3}

由于预训练规模大、时间长，一般不推荐使用 Jupyter Notebook
来运行，容易发生中断。且由于预训练规模大，一般需要使用多卡进行分布式训练，否则训练时间太长。在这里，我们介绍如何基于上述代码，使用
DeepSpeed 框架实现分布式训练，从而完成业界可用的 LLM Pretrain。

长时间训练一般使用 bash 脚本设定超参，再启动写好的 python
脚本实现训练。我们使用一个 Python
脚本（\texttt{./code/pretrain.py}）来实现训练全流程。

先导入所需第三方库：

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ logging}
\ImportTok{import}\NormalTok{ math}
\ImportTok{import}\NormalTok{ os}
\ImportTok{import}\NormalTok{ sys}
\ImportTok{from}\NormalTok{ dataclasses }\ImportTok{import}\NormalTok{ dataclass, field}
\ImportTok{from}\NormalTok{ torchdata.datapipes.}\BuiltInTok{iter} \ImportTok{import}\NormalTok{ IterableWrapper}
\ImportTok{from}\NormalTok{ itertools }\ImportTok{import}\NormalTok{ chain}
\ImportTok{import}\NormalTok{ deepspeed}
\ImportTok{from}\NormalTok{ typing }\ImportTok{import}\NormalTok{ Optional,List}

\ImportTok{import}\NormalTok{ datasets}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ torch}
\ImportTok{from}\NormalTok{ datasets }\ImportTok{import}\NormalTok{ load\_dataset}
\ImportTok{import}\NormalTok{ transformers}
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ (}
\NormalTok{    AutoConfig,}
\NormalTok{    AutoModelForCausalLM,}
\NormalTok{    AutoTokenizer,}
\NormalTok{    HfArgumentParser,}
\NormalTok{    Trainer,}
\NormalTok{    TrainingArguments,}
\NormalTok{    default\_data\_collator,}
\NormalTok{    set\_seed,}
\NormalTok{)}
\ImportTok{import}\NormalTok{ datetime}
\ImportTok{from}\NormalTok{ transformers.testing\_utils }\ImportTok{import}\NormalTok{ CaptureLogger}
\ImportTok{from}\NormalTok{ transformers.trainer\_utils }\ImportTok{import}\NormalTok{ get\_last\_checkpoint}
\ImportTok{import}\NormalTok{ swanlab}
\end{Highlighting}
\end{Shaded}

首先需要定义几个超参的类型，用于处理 sh 脚本中设定的超参值。由于
transformers 本身有 TraingingArguments
类，其中包括了训练的一些必备超参数。我们这里只需定义 TrainingArguments
中未包含的超参即可，主要包括模型相关的超参（定义在
ModelArguments）和数据相关的超参（定义在 DataTrainingArguments）：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 超参类}
\AttributeTok{@dataclass}
\KeywordTok{class}\NormalTok{ ModelArguments:}
    \CommentTok{"""}
\CommentTok{    关于模型的参数}
\CommentTok{    """}

\NormalTok{    model\_name\_or\_path: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(}
\NormalTok{        default}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{        metadata}\OperatorTok{=}\NormalTok{\{}
            \StringTok{"help"}\NormalTok{: (}
                \StringTok{"后训练使用，为预训练模型参数地址"}
\NormalTok{            )}
\NormalTok{        \},}
\NormalTok{    )}
\NormalTok{    config\_name: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(}
\NormalTok{        default}\OperatorTok{=}\VariableTok{None}\NormalTok{, metadata}\OperatorTok{=}\NormalTok{\{}\StringTok{"help"}\NormalTok{: }\StringTok{"预训练使用，Config 文件地址"}\NormalTok{\}}
\NormalTok{    )}
\NormalTok{    tokenizer\_name: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(}
\NormalTok{        default}\OperatorTok{=}\VariableTok{None}\NormalTok{, metadata}\OperatorTok{=}\NormalTok{\{}\StringTok{"help"}\NormalTok{: }\StringTok{"预训练 Tokenizer 地址"}\NormalTok{\}}
\NormalTok{    )}
\NormalTok{    torch\_dtype: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(}
\NormalTok{        default}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{        metadata}\OperatorTok{=}\NormalTok{\{}
            \StringTok{"help"}\NormalTok{: (}
                \StringTok{"模型训练使用的数据类型，推荐 bfloat16"}
\NormalTok{            ),}
            \StringTok{"choices"}\NormalTok{: [}\StringTok{"auto"}\NormalTok{, }\StringTok{"bfloat16"}\NormalTok{, }\StringTok{"float16"}\NormalTok{, }\StringTok{"float32"}\NormalTok{],}
\NormalTok{        \},}
\NormalTok{    )}


\AttributeTok{@dataclass}
\KeywordTok{class}\NormalTok{ DataTrainingArguments:}
    \CommentTok{"""}
\CommentTok{    关于训练的参数}
\CommentTok{    """}

\NormalTok{    train\_files: Optional[List[}\BuiltInTok{str}\NormalTok{]]  }\OperatorTok{=}\NormalTok{ field(default}\OperatorTok{=}\VariableTok{None}\NormalTok{, metadata}\OperatorTok{=}\NormalTok{\{}\StringTok{"help"}\NormalTok{: }\StringTok{"训练数据路径"}\NormalTok{\})}
\NormalTok{    block\_size: Optional[}\BuiltInTok{int}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(}
\NormalTok{        default}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{        metadata}\OperatorTok{=}\NormalTok{\{}
            \StringTok{"help"}\NormalTok{: (}
                \StringTok{"设置的文本块长度"}
\NormalTok{            )}
\NormalTok{        \},}
\NormalTok{    )}
\NormalTok{    preprocessing\_num\_workers: Optional[}\BuiltInTok{int}\NormalTok{] }\OperatorTok{=}\NormalTok{ field(}
\NormalTok{        default}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{        metadata}\OperatorTok{=}\NormalTok{\{}\StringTok{"help"}\NormalTok{: }\StringTok{"预处理使用线程数."}\NormalTok{\},}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

然后即可定义一个主函数实现上述训练过程的封装。首先通过 transformers
提供的 HfArgumentParser 工具来加载 sh 脚本中设定的超参：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 加载脚本参数}
\NormalTok{parser }\OperatorTok{=}\NormalTok{ HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))}
\NormalTok{model\_args, data\_args, training\_args }\OperatorTok{=}\NormalTok{ parser.parse\_args\_into\_dataclasses()}
\end{Highlighting}
\end{Shaded}

在大规模的训练中，一般使用 log 来保存训练过程的信息，一般不推荐使用
print 直接打印，容易发生关键训练信息的丢失。这里，我们直接使用 python
自带的 logging 库来实现日志记录。首先需要进行 log 的设置：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 设置日志}
\NormalTok{logging.basicConfig(}
    \BuiltInTok{format}\OperatorTok{=}\StringTok{"}\SpecialCharTok{\%(asctime)s}\StringTok{ {-} }\SpecialCharTok{\%(levelname)s}\StringTok{ {-} }\SpecialCharTok{\%(name)s}\StringTok{ {-} }\SpecialCharTok{\%(message)s}\StringTok{"}\NormalTok{,}
\NormalTok{    datefmt}\OperatorTok{=}\StringTok{"\%m/}\SpecialCharTok{\%d}\StringTok{/\%Y \%H:\%M:\%S"}\NormalTok{,}
\NormalTok{    handlers}\OperatorTok{=}\NormalTok{[logging.StreamHandler(sys.stdout)],}
\NormalTok{)}

\CommentTok{\# 将日志级别设置为 INFO}
\NormalTok{transformers.utils.logging.set\_verbosity\_info()}
\NormalTok{log\_level }\OperatorTok{=}\NormalTok{ training\_args.get\_process\_log\_level()}
\NormalTok{logger.setLevel(log\_level)}
\NormalTok{datasets.utils.logging.set\_verbosity(log\_level)}
\NormalTok{transformers.utils.logging.set\_verbosity(log\_level)}
\NormalTok{transformers.utils.logging.enable\_default\_handler()}
\NormalTok{transformers.utils.logging.enable\_explicit\_format()}
\end{Highlighting}
\end{Shaded}

这里将日志的级别设置为 INFO。logging 的日志共有
DEBUG、INFO、WARNING、ERROR 以及 CRITICAL
五个级别，将日志设置为哪个级别，就会只输出该级别及该级别之上的信息。设置完成后，在需要记录日志的地方，直接使用
logger 即可，记录时会指定记录日志的级别，例如：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 训练整体情况记录}
\NormalTok{logger.warning(}
    \SpecialStringTok{f"Process rank: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{local\_rank}\SpecialCharTok{\}}\SpecialStringTok{, device: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{device}\SpecialCharTok{\}}\SpecialStringTok{, n\_gpu: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{n\_gpu}\SpecialCharTok{\}}\SpecialStringTok{"}
    \OperatorTok{+} \SpecialStringTok{f"distributed training: }\SpecialCharTok{\{}\BuiltInTok{bool}\NormalTok{(training\_args.local\_rank }\OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\SpecialCharTok{\}}\SpecialStringTok{, 16{-}bits training: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{fp16}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{)}
\NormalTok{logger.info(}\SpecialStringTok{f"Training/evaluation parameters }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

后续就不再赘述脚本中的日志记录。

在大规模训练中，发生中断是往往难以避免的，训练一般会固定间隔保存
checkpoint，中断之后基于最近的 checkpoint
恢复训练即可。因此，我们需要首先检测是否存在旧的 checkpoint 并从
checkpoint 恢复训练：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 检查 checkpoint}
\NormalTok{last\_checkpoint }\OperatorTok{=} \VariableTok{None}
\ControlFlowTok{if}\NormalTok{ os.path.isdir(training\_args.output\_dir):}
    \CommentTok{\# 使用 transformers 自带的 get\_last\_checkpoint 自动检测}
\NormalTok{    last\_checkpoint }\OperatorTok{=}\NormalTok{ get\_last\_checkpoint(training\_args.output\_dir)}
    \ControlFlowTok{if}\NormalTok{ last\_checkpoint }\KeywordTok{is} \VariableTok{None} \KeywordTok{and} \BuiltInTok{len}\NormalTok{(os.listdir(training\_args.output\_dir)) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}
            \SpecialStringTok{f"输出路径 (}\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{output\_dir}\SpecialCharTok{\}}\SpecialStringTok{) 非空 "}
\NormalTok{        )}
    \ControlFlowTok{elif}\NormalTok{ last\_checkpoint }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ training\_args.resume\_from\_checkpoint }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{        logger.info(}
            \SpecialStringTok{f"从 }\SpecialCharTok{\{}\NormalTok{last\_checkpoint}\SpecialCharTok{\}}\SpecialStringTok{恢复训练"}
\NormalTok{        )}
\end{Highlighting}
\end{Shaded}

接着以上文介绍过的方式初始化模型，此处将从零初始化和基于已有预训练模型初始化包装在一起：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 初始化模型}
\ControlFlowTok{if}\NormalTok{ model\_args.config\_name }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
    \CommentTok{\# from scrach}
\NormalTok{    config }\OperatorTok{=}\NormalTok{ AutoConfig.from\_pretrained(model\_args.config\_name)}
\NormalTok{    logger.warning(}\StringTok{"你正在从零初始化一个模型"}\NormalTok{)}
\NormalTok{    logger.info(}\SpecialStringTok{f"模型参数配置地址：}\SpecialCharTok{\{}\NormalTok{model\_args}\SpecialCharTok{.}\NormalTok{config\_name}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    logger.info(}\SpecialStringTok{f"模型参数：}\SpecialCharTok{\{}\NormalTok{config}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ AutoModelForCausalLM.from\_config(config,trust\_remote\_code}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    n\_params }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(\{p.data\_ptr(): p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters()\}.values())}
\NormalTok{    logger.info(}\SpecialStringTok{f"预训练一个新模型 {-} Total size=}\SpecialCharTok{\{}\NormalTok{n\_params}\OperatorTok{/}\DecValTok{2}\OperatorTok{**}\DecValTok{20}\SpecialCharTok{:.2f\}}\SpecialStringTok{M params"}\NormalTok{)}
\ControlFlowTok{elif}\NormalTok{ model\_args.model\_name\_or\_path }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{    logger.warning(}\StringTok{"你正在初始化一个预训练模型"}\NormalTok{)}
\NormalTok{    logger.info(}\SpecialStringTok{f"模型参数地址：}\SpecialCharTok{\{}\NormalTok{model\_args}\SpecialCharTok{.}\NormalTok{model\_name\_or\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ AutoModelForCausalLM.from\_pretrained(model\_args.model\_name\_or\_path,trust\_remote\_code}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    n\_params }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(\{p.data\_ptr(): p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters()\}.values())}
\NormalTok{    logger.info(}\SpecialStringTok{f"继承一个预训练模型 {-} Total size=}\SpecialCharTok{\{}\NormalTok{n\_params}\OperatorTok{/}\DecValTok{2}\OperatorTok{**}\DecValTok{20}\SpecialCharTok{:.2f\}}\SpecialStringTok{M params"}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    logger.error(}\StringTok{"config\_name 和 model\_name\_or\_path 不能均为空"}\NormalTok{)}
    \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\StringTok{"config\_name 和 model\_name\_or\_path 不能均为空"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

再类似的进行 tokenizer
的加载和预训练数据的处理。该部分和上文完全一致，此处不再赘述，读者可以在代码中详细查看细节。类似的，使用
Trainer 进行训练：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logger.info(}\StringTok{"初始化 Trainer"}\NormalTok{)}
\NormalTok{trainer }\OperatorTok{=}\NormalTok{ Trainer(}
\NormalTok{    model}\OperatorTok{=}\NormalTok{model,}
\NormalTok{    args}\OperatorTok{=}\NormalTok{training\_args,}
\NormalTok{    train\_dataset}\OperatorTok{=}\NormalTok{ IterableWrapper(train\_dataset),}
\NormalTok{    tokenizer}\OperatorTok{=}\NormalTok{tokenizer,}
\NormalTok{    data\_collator}\OperatorTok{=}\NormalTok{default\_data\_collator}
\NormalTok{)}

\CommentTok{\# 从 checkpoint 加载}
\NormalTok{checkpoint }\OperatorTok{=} \VariableTok{None}
\ControlFlowTok{if}\NormalTok{ training\_args.resume\_from\_checkpoint }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{    checkpoint }\OperatorTok{=}\NormalTok{ training\_args.resume\_from\_checkpoint}
\ControlFlowTok{elif}\NormalTok{ last\_checkpoint }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{        checkpoint }\OperatorTok{=}\NormalTok{ last\_checkpoint}

\NormalTok{logger.info(}\StringTok{"开始训练"}\NormalTok{)}
\NormalTok{train\_result }\OperatorTok{=}\NormalTok{ trainer.train(resume\_from\_checkpoint}\OperatorTok{=}\NormalTok{checkpoint)}
\NormalTok{trainer.save\_model() }
\end{Highlighting}
\end{Shaded}

注意，由于上文检测了是否存在 checkpoint，此处使用
resume\_from\_checkpoint 来实现从 checkpoint 恢复训练的功能。

由于在大规模训练中监测训练进度、loss
下降趋势尤为重要，在脚本中，我们使用了 swanlab
作为训练检测的工具。在脚本开始进行了 swanlab 的初始化：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 初始化 SwanLab}
\NormalTok{swanlab.init(project}\OperatorTok{=}\StringTok{"pretrain"}\NormalTok{, experiment\_name}\OperatorTok{=}\StringTok{"from\_scrach"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

在启动训练后，终端会输出 swanlab 监测的
url，点击即可观察训练进度。此处不再赘述 swanlab
的使用细节，欢迎读者查阅相关的资料说明。

完成上述代码后，我们使用一个 sh
脚本（\texttt{./code/pretrain.sh}）定义超参数的值，并通过 Deepspeed
启动训练，从而实现高效的多卡分布式训练：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 设置可见显卡}
\VariableTok{CUDA\_VISIBLE\_DEVICES}\OperatorTok{=}\NormalTok{0,1}

\ExtensionTok{deepspeed}\NormalTok{ pretrain.py }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}config\_name}\NormalTok{ autodl{-}tmp/qwen{-}1.5b }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}tokenizer\_name}\NormalTok{ autodl{-}tmp/qwen{-}1.5b }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}train\_files}\NormalTok{ autodl{-}tmp/dataset/pretrain\_data/mobvoi\_seq\_monkey\_general\_open\_corpus\_small.jsonl }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}per\_device\_train\_batch\_size}\NormalTok{ 16 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}gradient\_accumulation\_steps}\NormalTok{ 4 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}do\_train} \DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}output\_dir}\NormalTok{ autodl{-}tmp/output/pretrain }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}evaluation\_strategy}\NormalTok{  no }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}learning\_rate}\NormalTok{ 1e{-}4 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}num\_train\_epochs}\NormalTok{ 1 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}warmup\_steps}\NormalTok{ 200 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}logging\_dir}\NormalTok{ autodl{-}tmp/output/pretrain/logs }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}logging\_strategy}\NormalTok{ steps }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}logging\_steps}\NormalTok{ 5 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}save\_strategy}\NormalTok{ steps }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}save\_steps}\NormalTok{ 100 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}preprocessing\_num\_workers}\NormalTok{ 10 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}save\_total\_limit}\NormalTok{ 1 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}seed}\NormalTok{ 12 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}block\_size}\NormalTok{ 2048 }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}bf16} \DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}gradient\_checkpointing} \DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}deepspeed}\NormalTok{ ./ds\_config\_zero2.json }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}{-}report\_to}\NormalTok{ swanlab}
    \CommentTok{\# {-}{-}resume\_from\_checkpoint $\{output\_model\}/checkpoint{-}20400 \textbackslash{}}
\end{Highlighting}
\end{Shaded}

在安装了 Deepspeed 第三方库后，可以直接通过 Deepspeed
命令来启动多卡训练。上述脚本命令主要是定义了各种超参数的值，可参考使用。在第四章中，我们介绍了
DeepSpeed 分布式训练的原理和 ZeRO 阶段设置，在这里，我们使用 ZeRO-2
进行训练。此处加载了 \texttt{ds\_config\_zero.json} 作为 DeepSpeed
的配置参数：

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\{}
    \DataTypeTok{"fp16"}\FunctionTok{:} \FunctionTok{\{}
        \DataTypeTok{"enabled"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
        \DataTypeTok{"loss\_scale"}\FunctionTok{:} \DecValTok{0}\FunctionTok{,}
        \DataTypeTok{"loss\_scale\_window"}\FunctionTok{:} \DecValTok{1000}\FunctionTok{,}
        \DataTypeTok{"initial\_scale\_power"}\FunctionTok{:} \DecValTok{16}\FunctionTok{,}
        \DataTypeTok{"hysteresis"}\FunctionTok{:} \DecValTok{2}\FunctionTok{,}
        \DataTypeTok{"min\_loss\_scale"}\FunctionTok{:} \DecValTok{1}
    \FunctionTok{\},}
    \DataTypeTok{"bf16"}\FunctionTok{:} \FunctionTok{\{}
        \DataTypeTok{"enabled"}\FunctionTok{:} \StringTok{"auto"}
    \FunctionTok{\},}
    \DataTypeTok{"optimizer"}\FunctionTok{:} \FunctionTok{\{}
        \DataTypeTok{"type"}\FunctionTok{:} \StringTok{"AdamW"}\FunctionTok{,}
        \DataTypeTok{"params"}\FunctionTok{:} \FunctionTok{\{}
            \DataTypeTok{"lr"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
            \DataTypeTok{"betas"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
            \DataTypeTok{"eps"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
            \DataTypeTok{"weight\_decay"}\FunctionTok{:} \StringTok{"auto"}
        \FunctionTok{\}}
    \FunctionTok{\},}

    \DataTypeTok{"scheduler"}\FunctionTok{:} \FunctionTok{\{}
        \DataTypeTok{"type"}\FunctionTok{:} \StringTok{"WarmupLR"}\FunctionTok{,}
        \DataTypeTok{"params"}\FunctionTok{:} \FunctionTok{\{}
            \DataTypeTok{"warmup\_min\_lr"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
            \DataTypeTok{"warmup\_max\_lr"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
            \DataTypeTok{"warmup\_num\_steps"}\FunctionTok{:} \StringTok{"auto"}
        \FunctionTok{\}}
    \FunctionTok{\},}

    \DataTypeTok{"zero\_optimization"}\FunctionTok{:} \FunctionTok{\{}
        \DataTypeTok{"stage"}\FunctionTok{:} \DecValTok{2}\FunctionTok{,}
        \DataTypeTok{"offload\_optimizer"}\FunctionTok{:} \FunctionTok{\{}
            \DataTypeTok{"device"}\FunctionTok{:} \StringTok{"none"}\FunctionTok{,}
            \DataTypeTok{"pin\_memory"}\FunctionTok{:} \KeywordTok{true}
        \FunctionTok{\},}
        \DataTypeTok{"allgather\_partitions"}\FunctionTok{:} \KeywordTok{true}\FunctionTok{,}
        \DataTypeTok{"allgather\_bucket\_size"}\FunctionTok{:} \DecValTok{2e8}\FunctionTok{,}
        \DataTypeTok{"overlap\_comm"}\FunctionTok{:} \KeywordTok{true}\FunctionTok{,}
        \DataTypeTok{"reduce\_scatter"}\FunctionTok{:} \KeywordTok{true}\FunctionTok{,}
        \DataTypeTok{"reduce\_bucket\_size"}\FunctionTok{:} \DecValTok{2e8}\FunctionTok{,}
        \DataTypeTok{"contiguous\_gradients"}\FunctionTok{:} \KeywordTok{true}
    \FunctionTok{\},}

    \DataTypeTok{"gradient\_accumulation\_steps"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
    \DataTypeTok{"gradient\_clipping"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
    \DataTypeTok{"steps\_per\_print"}\FunctionTok{:} \DecValTok{100}\FunctionTok{,}
    \DataTypeTok{"train\_batch\_size"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
    \DataTypeTok{"train\_micro\_batch\_size\_per\_gpu"}\FunctionTok{:} \StringTok{"auto"}\FunctionTok{,}
    \DataTypeTok{"wall\_clock\_breakdown"}\FunctionTok{:} \KeywordTok{false}
\FunctionTok{\}}
\end{Highlighting}
\end{Shaded}

最后，在终端 bash 运行该 \texttt{pretrain.sh} 脚本即可开始训练。

\subsection{6.2
模型有监督微调}\label{ux6a21ux578bux6709ux76d1ux7763ux5faeux8c03}

在上一节，我们介绍了如何使用 Transformers
框架快速、高效地进行模型预训练。在本部分，我们将基于上部分内容，介绍如何使用
Transformers 框架对预训练好的模型进行有监督微调。

\subsubsection{6.2.1 Pretrain VS SFT}\label{pretrain-vs-sft}

首先需要回顾一下，对 LLM
进行预训练和进行有监督微调的核心差异在于什么。在第四章中提到过，目前成型的
LLM 一般通过 Pretrain-SFT-RLHF 三个阶段来训练，在 Pretrain
阶段，会对海量无监督文本进行自监督建模，来学习文本语义规则和文本中的世界知识；在
SFT 阶段，一般通过对 Pretrain
好的模型进行指令微调，即训练模型根据用户指令完成对应任务，从而使模型能够遵循用户指令，根据用户指令进行规划、行动和输出。因此，Pretrain
和 SFT 均使用 CLM 建模，其核心差异在于，Pretrain
使用海量无监督文本进行训练，模型直接对文本执行``预测下一个
token''的任务；而 SFT
使用构建成对的指令对数据，模型根据输入的指令，建模后续的输出。反映到具体的训练实现上，Pretrain
会对全部 text 进行 loss 计算，要求模型对整个文本实现建模预测；而 SFT
仅对输出进行 loss 计算，不计算指令部分的 loss。

因此，相较于上一节完成的 Pretrain 代码，SFT
部分仅需要修改数据处理环节，实现对指令对数据转化为训练样本的构建，其余部分和
Pretrain
是完全一致的实现逻辑。本部分代码脚本为\texttt{./code/finetune.py}。

\subsubsection{6.2.2
微调数据处理}\label{ux5faeux8c03ux6570ux636eux5904ux7406}

同样与第五章类似，我们此处使用贝壳开源的 BelleGroup 数据集进行 SFT。

在 SFT 过程中，我们会定义一个 Chat Template，这个 Template
即表示了如何将对话数据转化为一个模型可以建模拟合的文本序列。当我们使用做过
SFT 的模型进行下游任务微调时，一般需要查看该模型的 Chat Template
并进行适配，即是为了不损伤其在 SFT
中学到的指令遵循能力。由于我们此处使用 Pretrain 模型进行
SFT，可以自定义一个 Chat Template。由于我们使用了 Qwen-2.5-1.5B
模型结构进行 Pretrain，此处我们沿承使用 Qwen-2.5 的 Chat
Template。如果读者没有足够的资源进行上一部分模型的 Pretrain
的话，此处也可以使用官方的 Qwen-2.5-1.5B 模型作为 SFT 的基座模型。

我们首先定义几个特殊 token，特殊 token
在模型进行拟合中有特殊的作用，包括文本序列开始（BOS）、文本序列结束（EOS）、换行符等。定义特殊
token，有助于避免模型在拟合过程中的语义混淆：

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# 不同的 tokenizer 需要特别定义}
\CommentTok{\# BOS}
\NormalTok{im\_start }\OperatorTok{=}\NormalTok{ tokenizer(}\StringTok{"\textless{}|im\_start|\textgreater{}"}\NormalTok{).input\_ids}
\CommentTok{\# EOS}
\NormalTok{im\_end }\OperatorTok{=}\NormalTok{ tokenizer(}\StringTok{"\textless{}|im\_end|\textgreater{}"}\NormalTok{).input\_ids}
\CommentTok{\# PAD}
\NormalTok{IGNORE\_TOKEN\_ID }\OperatorTok{=}\NormalTok{ tokenizer.pad\_token\_id}
\CommentTok{\# 换行符}
\NormalTok{nl\_tokens }\OperatorTok{=}\NormalTok{ tokenizer(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{).input\_ids}
\CommentTok{\# 角色标识符}
\NormalTok{\_system }\OperatorTok{=}\NormalTok{ tokenizer(}\StringTok{\textquotesingle{}system\textquotesingle{}}\NormalTok{).input\_ids }\OperatorTok{+}\NormalTok{ nl\_tokens}
\NormalTok{\_user }\OperatorTok{=}\NormalTok{ tokenizer(}\StringTok{\textquotesingle{}human\textquotesingle{}}\NormalTok{).input\_ids }\OperatorTok{+}\NormalTok{ nl\_tokens}
\NormalTok{\_assistant }\OperatorTok{=}\NormalTok{ tokenizer(}\StringTok{\textquotesingle{}assistant\textquotesingle{}}\NormalTok{).input\_ids }\OperatorTok{+}\NormalTok{ nl\_tokens}
\end{Highlighting}
\end{Shaded}

Qwen 系列的 Chat Template 一般有三个对话角色：System、User 和
Assistant。System 是系统提示词，负责激活模型的能力，默认为``You are a
helpful assistant.''，一般不会在 SFT 过程中更改使用。User
即为用户给出的提示词，此处由于数据集中的对话角色为 ``human''，我们将
``user'' 修改为了``human''。Assistant 即为 LLM 给出的回复，也就是模型在
SFT 过程中需要拟合的文本。

接着，由于该数据集是一个多轮对话数据集，我们需要对多轮对话进行拼接处理，将多轮对话拼接到一个文本序列中：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 拼接多轮对话}
\NormalTok{input\_ids, targets }\OperatorTok{=}\NormalTok{ [], []}
\CommentTok{\# 多个样本}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ tqdm(}\BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(sources))):}
    \CommentTok{\# source 为一个多轮对话样本}
\NormalTok{    source }\OperatorTok{=}\NormalTok{ sources[i]}
    \CommentTok{\# 从 user 开始}
    \ControlFlowTok{if}\NormalTok{ source[}\DecValTok{0}\NormalTok{][}\StringTok{"from"}\NormalTok{] }\OperatorTok{!=} \StringTok{"human"}\NormalTok{:}
\NormalTok{        source }\OperatorTok{=}\NormalTok{ source[}\DecValTok{1}\NormalTok{:]}
    \CommentTok{\# 分别是输入和输出}
\NormalTok{    input\_id, target }\OperatorTok{=}\NormalTok{ [], []}
    \CommentTok{\# system: 【BOS】system\textbackslash{}nYou are a helpful assistant.【EOS】\textbackslash{}n}
\NormalTok{    system }\OperatorTok{=}\NormalTok{ im\_start }\OperatorTok{+}\NormalTok{ \_system }\OperatorTok{+}\NormalTok{ tokenizer(system\_message).input\_ids }\OperatorTok{+}\NormalTok{ im\_end }\OperatorTok{+}\NormalTok{ nl\_tokens}
\NormalTok{    input\_id }\OperatorTok{+=}\NormalTok{ system}
    \CommentTok{\# system 不需要拟合}
\NormalTok{    target }\OperatorTok{+=}\NormalTok{ im\_start }\OperatorTok{+}\NormalTok{ [IGNORE\_TOKEN\_ID] }\OperatorTok{*}\NormalTok{ (}\BuiltInTok{len}\NormalTok{(system)}\OperatorTok{{-}}\DecValTok{3}\NormalTok{) }\OperatorTok{+}\NormalTok{ im\_end }\OperatorTok{+}\NormalTok{ nl\_tokens}
    \ControlFlowTok{assert} \BuiltInTok{len}\NormalTok{(input\_id) }\OperatorTok{==} \BuiltInTok{len}\NormalTok{(target)}
    \CommentTok{\# 依次拼接}
    \ControlFlowTok{for}\NormalTok{ j, sentence }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(source):}
        \CommentTok{\# sentence 为一轮对话}
\NormalTok{        role }\OperatorTok{=}\NormalTok{ roles[sentence[}\StringTok{"from"}\NormalTok{]]}
        \CommentTok{\# user：\textless{}|im\_start|\textgreater{}human\textbackslash{}ninstruction【EOS】\textbackslash{}n}
        \CommentTok{\# assistant：\textless{}|im\_start|\textgreater{}assistant\textbackslash{}nresponse【EOS】\textbackslash{}n}
\NormalTok{        \_input\_id }\OperatorTok{=}\NormalTok{ tokenizer(role).input\_ids }\OperatorTok{+}\NormalTok{ nl\_tokens }\OperatorTok{+} \OperatorTok{\textbackslash{}}
\NormalTok{            tokenizer(sentence[}\StringTok{"value"}\NormalTok{]).input\_ids }\OperatorTok{+}\NormalTok{ im\_end }\OperatorTok{+}\NormalTok{ nl\_tokens}
\NormalTok{        input\_id }\OperatorTok{+=}\NormalTok{ \_input\_id}
        \ControlFlowTok{if}\NormalTok{ role }\OperatorTok{==} \StringTok{\textquotesingle{}\textless{}|im\_start|\textgreater{}human\textquotesingle{}}\NormalTok{:}
            \CommentTok{\# user 不需要拟合}
\NormalTok{            \_target }\OperatorTok{=}\NormalTok{ im\_start }\OperatorTok{+}\NormalTok{ [IGNORE\_TOKEN\_ID] }\OperatorTok{*}\NormalTok{ (}\BuiltInTok{len}\NormalTok{(\_input\_id)}\OperatorTok{{-}}\DecValTok{3}\NormalTok{) }\OperatorTok{+}\NormalTok{ im\_end }\OperatorTok{+}\NormalTok{ nl\_tokens}
        \ControlFlowTok{elif}\NormalTok{ role }\OperatorTok{==} \StringTok{\textquotesingle{}\textless{}|im\_start|\textgreater{}assistant\textquotesingle{}}\NormalTok{:}
            \CommentTok{\# assistant 需要拟合}
\NormalTok{            \_target }\OperatorTok{=}\NormalTok{ im\_start }\OperatorTok{+}\NormalTok{ [IGNORE\_TOKEN\_ID] }\OperatorTok{*} \BuiltInTok{len}\NormalTok{(tokenizer(role).input\_ids) }\OperatorTok{+} \OperatorTok{\textbackslash{}}
\NormalTok{                \_input\_id[}\BuiltInTok{len}\NormalTok{(tokenizer(role).input\_ids)}\OperatorTok{+}\DecValTok{1}\NormalTok{:}\OperatorTok{{-}}\DecValTok{2}\NormalTok{] }\OperatorTok{+}\NormalTok{ im\_end }\OperatorTok{+}\NormalTok{ nl\_tokens}
        \ControlFlowTok{else}\NormalTok{:}
            \BuiltInTok{print}\NormalTok{(role)}
            \ControlFlowTok{raise} \PreprocessorTok{NotImplementedError}
\NormalTok{        target }\OperatorTok{+=}\NormalTok{ \_target}
    \ControlFlowTok{assert} \BuiltInTok{len}\NormalTok{(input\_id) }\OperatorTok{==} \BuiltInTok{len}\NormalTok{(target)}
    \CommentTok{\# 最后进行 PAD}
\NormalTok{    input\_id }\OperatorTok{+=}\NormalTok{ [tokenizer.pad\_token\_id] }\OperatorTok{*}\NormalTok{ (max\_len }\OperatorTok{{-}} \BuiltInTok{len}\NormalTok{(input\_id))}
\NormalTok{    target }\OperatorTok{+=}\NormalTok{ [IGNORE\_TOKEN\_ID] }\OperatorTok{*}\NormalTok{ (max\_len }\OperatorTok{{-}} \BuiltInTok{len}\NormalTok{(target))}
\NormalTok{    input\_ids.append(input\_id[:max\_len])}
\NormalTok{    targets.append(target[:max\_len])}
\end{Highlighting}
\end{Shaded}

上述代码沿承了 Qwen 的 Chat Template
逻辑，读者也可以根据自己的偏好进行修改，其核心点在于 User
的文本不需要拟合，因此 targets 中 User 对应的文本内容是使用的
IGNORE\_TOKEN\_ID 进行遮蔽，而 Assistant
对应的文本内容则是文本原文，是需要计算 loss 的。目前主流 LLM
IGNORE\_TOKEN\_ID 一般设置为 -100。

完成拼接后，将 tokenize 后的数值序列转化为
\texttt{Torch.tensor}，再拼接成 Dataset 所需的字典返回即可：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{input\_ids }\OperatorTok{=}\NormalTok{ torch.tensor(input\_ids)}
\NormalTok{targets }\OperatorTok{=}\NormalTok{ torch.tensor(targets)}

\ControlFlowTok{return} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    input\_ids}\OperatorTok{=}\NormalTok{input\_ids,}
\NormalTok{    labels}\OperatorTok{=}\NormalTok{targets,}
\NormalTok{    attention\_mask}\OperatorTok{=}\NormalTok{input\_ids.ne(tokenizer.pad\_token\_id),}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

完成上述处理逻辑后，需要自定义一个 Dataset
类，在该类中调用该逻辑进行数据的处理：

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ SupervisedDataset(Dataset):}

    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, raw\_data, tokenizer, max\_len: }\BuiltInTok{int}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{(SupervisedDataset, }\VariableTok{self}\NormalTok{).}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \CommentTok{\# 加载并预处理数据}
\NormalTok{        sources }\OperatorTok{=}\NormalTok{ [example[}\StringTok{"conversations"}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ example }\KeywordTok{in}\NormalTok{ raw\_data]}
        \CommentTok{\# preprocess 即上文定义的数据预处理逻辑}
\NormalTok{        data\_dict }\OperatorTok{=}\NormalTok{ preprocess(sources, tokenizer, max\_len)}

        \VariableTok{self}\NormalTok{.input\_ids }\OperatorTok{=}\NormalTok{ data\_dict[}\StringTok{"input\_ids"}\NormalTok{]}
        \VariableTok{self}\NormalTok{.labels }\OperatorTok{=}\NormalTok{ data\_dict[}\StringTok{"labels"}\NormalTok{]}
        \VariableTok{self}\NormalTok{.attention\_mask }\OperatorTok{=}\NormalTok{ data\_dict[}\StringTok{"attention\_mask"}\NormalTok{]}

    \KeywordTok{def} \FunctionTok{\_\_len\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.input\_ids)}

    \KeywordTok{def} \FunctionTok{\_\_getitem\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, i) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Dict[}\BuiltInTok{str}\NormalTok{, torch.Tensor]:}
        \ControlFlowTok{return} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{            input\_ids}\OperatorTok{=}\VariableTok{self}\NormalTok{.input\_ids[i],}
\NormalTok{            labels}\OperatorTok{=}\VariableTok{self}\NormalTok{.labels[i],}
\NormalTok{            attention\_mask}\OperatorTok{=}\VariableTok{self}\NormalTok{.attention\_mask[i],}
\NormalTok{        )}
\end{Highlighting}
\end{Shaded}

该类继承自 Torch 的 Dataset 类，可以直接在 Trainer
中使用。完成数据处理后，基于上一节脚本，修改数据处理逻辑即可，后续模型训练等几乎完全一致，此处附上主函数逻辑：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 加载脚本参数}
\NormalTok{parser }\OperatorTok{=}\NormalTok{ HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))}
\NormalTok{model\_args, data\_args, training\_args }\OperatorTok{=}\NormalTok{ parser.parse\_args\_into\_dataclasses()}

\CommentTok{\# 初始化 SwanLab}
\NormalTok{swanlab.init(project}\OperatorTok{=}\StringTok{"sft"}\NormalTok{, experiment\_name}\OperatorTok{=}\StringTok{"qwen{-}1.5b"}\NormalTok{)}

\CommentTok{\# 设置日志}
\NormalTok{logging.basicConfig(}
    \BuiltInTok{format}\OperatorTok{=}\StringTok{"}\SpecialCharTok{\%(asctime)s}\StringTok{ {-} }\SpecialCharTok{\%(levelname)s}\StringTok{ {-} }\SpecialCharTok{\%(name)s}\StringTok{ {-} }\SpecialCharTok{\%(message)s}\StringTok{"}\NormalTok{,}
\NormalTok{    datefmt}\OperatorTok{=}\StringTok{"\%m/}\SpecialCharTok{\%d}\StringTok{/\%Y \%H:\%M:\%S"}\NormalTok{,}
\NormalTok{    handlers}\OperatorTok{=}\NormalTok{[logging.StreamHandler(sys.stdout)],}
\NormalTok{)}

\CommentTok{\# 将日志级别设置为 INFO}
\NormalTok{transformers.utils.logging.set\_verbosity\_info()}
\NormalTok{log\_level }\OperatorTok{=}\NormalTok{ training\_args.get\_process\_log\_level()}
\NormalTok{logger.setLevel(log\_level)}
\NormalTok{datasets.utils.logging.set\_verbosity(log\_level)}
\NormalTok{transformers.utils.logging.set\_verbosity(log\_level)}
\NormalTok{transformers.utils.logging.enable\_default\_handler()}
\NormalTok{transformers.utils.logging.enable\_explicit\_format()}

\CommentTok{\# 训练整体情况记录}
\NormalTok{logger.warning(}
    \SpecialStringTok{f"Process rank: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{local\_rank}\SpecialCharTok{\}}\SpecialStringTok{, device: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{device}\SpecialCharTok{\}}\SpecialStringTok{, n\_gpu: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{n\_gpu}\SpecialCharTok{\}}\SpecialStringTok{"}
    \OperatorTok{+} \SpecialStringTok{f"distributed training: }\SpecialCharTok{\{}\BuiltInTok{bool}\NormalTok{(training\_args.local\_rank }\OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\SpecialCharTok{\}}\SpecialStringTok{, 16{-}bits training: }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{fp16}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{)}
\NormalTok{logger.info(}\SpecialStringTok{f"Training/evaluation parameters }\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\CommentTok{\# 检查 checkpoint}
\NormalTok{last\_checkpoint }\OperatorTok{=} \VariableTok{None}
\ControlFlowTok{if}\NormalTok{ os.path.isdir(training\_args.output\_dir):}
\NormalTok{    last\_checkpoint }\OperatorTok{=}\NormalTok{ get\_last\_checkpoint(training\_args.output\_dir)}
    \ControlFlowTok{if}\NormalTok{ last\_checkpoint }\KeywordTok{is} \VariableTok{None} \KeywordTok{and} \BuiltInTok{len}\NormalTok{(os.listdir(training\_args.output\_dir)) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}
            \SpecialStringTok{f"输出路径 (}\SpecialCharTok{\{}\NormalTok{training\_args}\SpecialCharTok{.}\NormalTok{output\_dir}\SpecialCharTok{\}}\SpecialStringTok{) 非空 "}
\NormalTok{        )}
    \ControlFlowTok{elif}\NormalTok{ last\_checkpoint }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ training\_args.resume\_from\_checkpoint }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{        logger.info(}
            \SpecialStringTok{f"从 }\SpecialCharTok{\{}\NormalTok{last\_checkpoint}\SpecialCharTok{\}}\SpecialStringTok{恢复训练"}
\NormalTok{        )}

\CommentTok{\# 设置随机数种子.}
\NormalTok{set\_seed(training\_args.seed)}

\CommentTok{\# 初始化模型}
\NormalTok{logger.warning(}\StringTok{"加载预训练模型"}\NormalTok{)}
\NormalTok{logger.info(}\SpecialStringTok{f"模型参数地址：}\SpecialCharTok{\{}\NormalTok{model\_args}\SpecialCharTok{.}\NormalTok{model\_name\_or\_path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{model }\OperatorTok{=}\NormalTok{ AutoModelForCausalLM.from\_pretrained(model\_args.model\_name\_or\_path,trust\_remote\_code}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{n\_params }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(\{p.data\_ptr(): p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters()\}.values())}
\NormalTok{logger.info(}\SpecialStringTok{f"继承一个预训练模型 {-} Total size=}\SpecialCharTok{\{}\NormalTok{n\_params}\OperatorTok{/}\DecValTok{2}\OperatorTok{**}\DecValTok{20}\SpecialCharTok{:.2f\}}\SpecialStringTok{M params"}\NormalTok{)}

\CommentTok{\# 初始化 Tokenizer}
\NormalTok{tokenizer }\OperatorTok{=}\NormalTok{ AutoTokenizer.from\_pretrained(model\_args.model\_name\_or\_path)}
\NormalTok{logger.info(}\StringTok{"完成 tokenzier 加载"}\NormalTok{)}

\CommentTok{\# 加载微调数据}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(data\_args.train\_files) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    lst }\OperatorTok{=}\NormalTok{ [json.loads(line) }\ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ f.readlines()[:}\DecValTok{10000}\NormalTok{]]}
\NormalTok{logger.info(}\StringTok{"完成训练集加载"}\NormalTok{)}
\NormalTok{logger.info(}\SpecialStringTok{f"训练集地址：}\SpecialCharTok{\{}\NormalTok{data\_args}\SpecialCharTok{.}\NormalTok{train\_files}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{logger.info(}\SpecialStringTok{f\textquotesingle{}训练样本总数:}\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(lst)}\SpecialCharTok{\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
\CommentTok{\# logger.info(f"训练集采样：\{ds["train"][0]\}")}

\NormalTok{train\_dataset }\OperatorTok{=}\NormalTok{ SupervisedDataset(lst, tokenizer}\OperatorTok{=}\NormalTok{tokenizer, max\_len}\OperatorTok{=}\DecValTok{2048}\NormalTok{)}

\NormalTok{logger.info(}\StringTok{"初始化 Trainer"}\NormalTok{)}
\NormalTok{trainer }\OperatorTok{=}\NormalTok{ Trainer(}
\NormalTok{    model}\OperatorTok{=}\NormalTok{model,}
\NormalTok{    args}\OperatorTok{=}\NormalTok{training\_args,}
\NormalTok{    train\_dataset}\OperatorTok{=}\NormalTok{ IterableWrapper(train\_dataset),}
\NormalTok{    tokenizer}\OperatorTok{=}\NormalTok{tokenizer}
\NormalTok{)}

\CommentTok{\# 从 checkpoint 加载}
\NormalTok{checkpoint }\OperatorTok{=} \VariableTok{None}
\ControlFlowTok{if}\NormalTok{ training\_args.resume\_from\_checkpoint }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{    checkpoint }\OperatorTok{=}\NormalTok{ training\_args.resume\_from\_checkpoint}
\ControlFlowTok{elif}\NormalTok{ last\_checkpoint }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{        checkpoint }\OperatorTok{=}\NormalTok{ last\_checkpoint}

\NormalTok{logger.info(}\StringTok{"开始训练"}\NormalTok{)}
\NormalTok{train\_result }\OperatorTok{=}\NormalTok{ trainer.train(resume\_from\_checkpoint}\OperatorTok{=}\NormalTok{checkpoint)}
\NormalTok{trainer.save\_model() }
\end{Highlighting}
\end{Shaded}

启动方式也同样在 sh 脚本中使用 deepspeed 启动即可，此处不再赘述，源码见
./code/finetune.sh。

\subsection{6.3 高效微调}\label{ux9ad8ux6548ux5faeux8c03}

在前面几节，我们详细介绍了基于 Transformers 框架对模型进行 Pretrain、SFT
以及 RLHF 的原理和实践细节。但是，由于 LLM
参数量大，训练数据多，通过上述方式对模型进行训练（主要指 SFT 及
RLHF）需要调整模型全部参数，资源压力非常大。对资源有限的企业或课题组来说，如何高效、快速对模型进行领域或任务的微调，以低成本地使用
LLM 完成目标任务，是非常重要的。

\subsubsection{6.3.1
高效微调方案}\label{ux9ad8ux6548ux5faeux8c03ux65b9ux6848}

针对全量微调的昂贵问题，目前主要有两种解决方案：

\textbf{Adapt Tuning}。即在模型中添加 Adapter
层，在微调时冻结原参数，仅更新 Adapter 层。

具体而言，其在预训练模型每层中插入用于下游任务的参数，即 Adapter
模块，在微调时冻结模型主体，仅训练特定于任务的参数，如图6.8所示。

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/3-1.png" alt="alt text" width="90%" />
<p>图6.8 Adapt Tuning</p>
\end{verbatim}

每个 Adapter 模块由两个前馈子层组成，第一个前馈子层将 Transformer
块的输出作为输入，将原始输入维度 \(d\) 投影到 \(m\)，通过控制 \(m\)
的大小来限制 Adapter 模块的参数量，通常情况下
\(m << d\)。在输出阶段，通过第二个前馈子层还原输入维度，将 \(m\)
重新投影到 \(d\)，作为 Adapter 模块的输出(如上图右侧结构)。

LoRA 事实上就是一种改进的 Adapt Tuning 方法。但 Adapt Tuning
方法存在推理延迟问题，由于增加了额外参数和额外计算量，导致微调之后的模型计算速度相较原预训练模型更慢。

\textbf{Prefix Tuning}。该种方法固定预训练 LM，为 LM
添加可训练，任务特定的前缀，这样就可以为不同任务保存不同的前缀，微调成本也小。具体而言，在每一个输入
token 前构造一段与下游任务相关的 virtual tokens 作为
prefix，在微调时只更新 prefix 部分的参数，而其他参数冻结不变。

也是目前常用的微量微调方法的 Ptuning，其实就是 Prefix Tuning
的一种改进。但 Prefix Tuning
也存在固定的缺陷：模型可用序列长度减少。由于加入了 virtual
tokens，占用了可用序列长度，因此越高的微调质量，模型可用序列长度就越低。

\subsubsection{6.3.2 LoRA 微调}\label{lora-ux5faeux8c03}

如果一个大模型是将数据映射到高维空间进行处理，这里假定在处理一个细分的小任务时，是不需要那么复杂的大模型的，可能只需要在某个子空间范围内就可以解决，那么也就不需要对全量参数进行优化了，我们可以定义当对某个子空间参数进行优化时，能够达到全量参数优化的性能的一定水平（如90\%精度）时，那么这个子空间参数矩阵的秩就可以称为对应当前待解决问题的本征秩（intrinsic
rank）。

预训练模型本身就隐式地降低了本征秩，当针对特定任务进行微调后，模型中权重矩阵其实具有更低的本征秩（intrinsic
rank）。同时，越简单的下游任务，对应的本征秩越低。（\href{https://arxiv.org/abs/2012.13255}{Intrinsic
Dimensionality Explains the Effectiveness of Language Model
Fine-Tuning}）因此，权重更新的那部分参数矩阵尽管随机投影到较小的子空间，仍然可以有效的学习，可以理解为针对特定的下游任务这些权重矩阵就不要求满秩。我们可以通过优化密集层在适应过程中变化的秩分解矩阵来间接训练神经网络中的一些密集层，从而实现仅优化密集层的秩分解矩阵来达到微调效果。

例如，假设预训练参数为
\(\theta^D_0\)，在特定下游任务上密集层权重参数矩阵对应的本征秩为
\(\theta^d\)，对应特定下游任务微调参数为 \(\theta^D\)，那么有：

\[\theta^D = \theta^D_0 + \theta^d M\]

这个 \(M\) 即为 LoRA 优化的秩分解矩阵。

想对于其他高效微调方法，LoRA 存在以下优势：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  可以针对不同的下游任务构建小型 LoRA
  模块，从而在共享预训练模型参数基础上有效地切换下游任务。
\item
  LoRA 使用自适应优化器（Adaptive
  Optimizer），不需要计算梯度或维护大多数参数的优化器状态，训练更有效、硬件门槛更低。
\item
  LoRA
  使用简单的线性设计，在部署时将可训练矩阵与冻结权重合并，不存在推理延迟。
\item
  LoRA 与其他方法正交，可以组合。
\end{enumerate}

因此，LoRA 成为目前高效微调 LLM
的主流方法，尤其是对于资源受限、有监督训练数据受限的情况下，LoRA
微调往往会成为 LLM 微调的首选方法。

\subsubsection{6.3.3 LoRA
微调的原理}\label{lora-ux5faeux8c03ux7684ux539fux7406}

\paragraph{（1）低秩参数化更新矩阵}\label{ux4f4eux79e9ux53c2ux6570ux5316ux66f4ux65b0ux77e9ux9635}

LoRA 假设权重更新的过程中也有一个较低的本征秩，对于预训练的权重参数矩阵
\(W0 \in R^{d \times k}\) (\(d\) 为上一层输出维度，\(k\)
为下一层输入维度)，使用低秩分解来表示其更新：

\[W_0 + {\Delta}W = W_0 + BA \space\space  where \space B \in R^{d \times r}, A \in R^{r \times k}\]

在训练过程中，\(W_0\) 冻结不更新，\(A\)、\(B\) 包含可训练参数。

因此，LoRA 的前向传递函数为：

\[h = W_0 x + \Delta W x = W_0 x + B A x\]

在开始训练时，对 \(A\) 使用随机高斯初始化，对 \(B\)
使用零初始化，然后使用 Adam 进行优化。

训练思路如图6.9所示：

\begin{verbatim}
<img src="https://raw.githubusercontent.com/datawhalechina/happy-llm/main/docs/images/6-images/3-2.jpg" alt="alt text" width="90%" />
<p>图6.9 LoRA</p>
\end{verbatim}

\paragraph{（2）应用于
Transformer}\label{ux5e94ux7528ux4e8e-transformer}

在 Transformer 结构中，LoRA
技术主要应用在注意力模块的四个权重矩阵：\(W_q\)、\(W_k\)、\(W_v\)、\(W_0\)，而冻结
MLP 的权重矩阵。

通过消融实验发现同时调整 \(W_q\) 和 \(W_v\) 会产生最佳结果。

在上述条件下，可训练参数个数为：

\[\Theta = 2 \times L_{LoRA} \times d_{model} \times r\]

其中，\(L_{LoRA}\) 为应用 LoRA 的权重矩阵的个数，\(d_{model}\) 为
Transformer 的输入输出维度，\(r\) 为设定的 LoRA 秩。

一般情况下，r 取到 4、8、16。

\subsubsection{6.3.4 LoRA
的代码实现}\label{lora-ux7684ux4ee3ux7801ux5b9eux73b0}

目前一般通过 peft 库来实现模型的 LoRA 微调。peft 库是 huggingface
开发的第三方库，其中封装了包括 LoRA、Adapt Tuning、P-tuning
等多种高效微调方法，可以基于此便捷地实现模型的 LoRA 微调。

本文简单解析 peft 库中的 LoRA 微调代码，简单分析 LoRA 微调的代码实现。

\paragraph{（1）实现流程}\label{ux5b9eux73b0ux6d41ux7a0b}

LoRA 微调的内部实现流程主要包括以下几个步骤：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  确定要使用 LoRA 的层。peft 库目前支持调用 LoRA
  的层包括：nn.Linear、nn.Embedding、nn.Conv2d 三种。
\item
  对每一个要使用 LoRA 的层，替换为 LoRA 层。所谓 LoRA
  层，实则是在该层原结果基础上增加了一个旁路，通过低秩分解（即矩阵 \(A\)
  和矩阵 \(B\)）来模拟参数更新。
\item
  冻结原参数，进行微调，更新 LoRA 层参数。
\end{enumerate}

\paragraph{（2）确定 LoRA 层}\label{ux786eux5b9a-lora-ux5c42}

在进行 LoRA 微调时，首先需要确定 LoRA 微调参数，其中一个重要参数即是
target\_modules。target\_modules
一般是一个字符串列表，每一个字符串是需要进行 LoRA 的层名称，例如：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{target\_modules }\OperatorTok{=}\NormalTok{ [}\StringTok{"q\_proj"}\NormalTok{,}\StringTok{"v\_proj"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

这里的 q\_proj 即为注意力机制中的 \(W_q\)， v\_proj 即为注意力机制中的
\(W_v\)。我们可以根据模型架构和任务要求自定义需要进行 LoRA 操作的层。

在创建 LoRA
模型时，会获取该参数，然后在原模型中找到对应的层，该操作主要通过使用 re
对层名进行正则匹配实现：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 找到模型的各个组件中，名字里带"q\_proj"，"v\_proj"的}
\NormalTok{target\_module\_found }\OperatorTok{=}\NormalTok{ re.fullmatch(}\VariableTok{self}\NormalTok{.peft\_config.target\_modules, key)}
\CommentTok{\# 这里的 key，是模型的组件名}
\end{Highlighting}
\end{Shaded}

\paragraph{（3）替换 LoRA 层}\label{ux66ffux6362-lora-ux5c42}

对于找到的每一个目标层，会创建一个新的 LoRA 层进行替换。

LoRA 层在具体实现上，是定义了一个基于 Lora 基类的 Linear
类，该类同时继承了 nn.Linear 和 LoraLayer。LoraLayer 即是 Lora
基类，其主要构造了 LoRA 的各种超参：

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ LoraLayer:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}
        \VariableTok{self}\NormalTok{,}
\NormalTok{        r: }\BuiltInTok{int}\NormalTok{, }\CommentTok{\# LoRA 的秩}
\NormalTok{        lora\_alpha: }\BuiltInTok{int}\NormalTok{, }\CommentTok{\# 归一化参数}
\NormalTok{        lora\_dropout: }\BuiltInTok{float}\NormalTok{, }\CommentTok{\# LoRA 层的 dropout 比例}
\NormalTok{        merge\_weights: }\BuiltInTok{bool}\NormalTok{, }\CommentTok{\# eval 模式中，是否将 LoRA 矩阵的值加到原权重矩阵上}
\NormalTok{    ):}
        \VariableTok{self}\NormalTok{.r }\OperatorTok{=}\NormalTok{ r}
        \VariableTok{self}\NormalTok{.lora\_alpha }\OperatorTok{=}\NormalTok{ lora\_alpha}
        \CommentTok{\# Optional dropout}
        \ControlFlowTok{if}\NormalTok{ lora\_dropout }\OperatorTok{\textgreater{}} \FloatTok{0.0}\NormalTok{:}
            \VariableTok{self}\NormalTok{.lora\_dropout }\OperatorTok{=}\NormalTok{ nn.Dropout(p}\OperatorTok{=}\NormalTok{lora\_dropout)}
        \ControlFlowTok{else}\NormalTok{:}
            \VariableTok{self}\NormalTok{.lora\_dropout }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ x: x}
        \CommentTok{\# Mark the weight as unmerged}
        \VariableTok{self}\NormalTok{.merged }\OperatorTok{=} \VariableTok{False}
        \VariableTok{self}\NormalTok{.merge\_weights }\OperatorTok{=}\NormalTok{ merge\_weights}
        \VariableTok{self}\NormalTok{.disable\_adapters }\OperatorTok{=} \VariableTok{False}
\end{Highlighting}
\end{Shaded}

nn.Linear 就是 Pytorch 的线性层实现。Linear 类就是具体的 LoRA
层，其主要实现如下：

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ Linear(nn.Linear, LoraLayer):}
    \CommentTok{\# LoRA 层}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}
        \VariableTok{self}\NormalTok{,}
\NormalTok{        in\_features: }\BuiltInTok{int}\NormalTok{,}
\NormalTok{        out\_features: }\BuiltInTok{int}\NormalTok{,}
\NormalTok{        r: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{0}\NormalTok{,}
\NormalTok{        lora\_alpha: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{1}\NormalTok{,}
\NormalTok{        lora\_dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.0}\NormalTok{,}
\NormalTok{        fan\_in\_fan\_out: }\BuiltInTok{bool} \OperatorTok{=} \VariableTok{False}\NormalTok{, }
\NormalTok{        merge\_weights: }\BuiltInTok{bool} \OperatorTok{=} \VariableTok{True}\NormalTok{,}
        \OperatorTok{**}\NormalTok{kwargs,}
\NormalTok{    ):}
        \CommentTok{\# 继承两个基类的构造函数}
\NormalTok{        nn.Linear.}\FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_features, out\_features, }\OperatorTok{**}\NormalTok{kwargs)}
\NormalTok{        LoraLayer.}\FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, r}\OperatorTok{=}\NormalTok{r, lora\_alpha}\OperatorTok{=}\NormalTok{lora\_alpha, lora\_dropout}\OperatorTok{=}\NormalTok{lora\_dropout, merge\_weights}\OperatorTok{=}\NormalTok{merge\_weights)}

        \VariableTok{self}\NormalTok{.fan\_in\_fan\_out }\OperatorTok{=}\NormalTok{ fan\_in\_fan\_out}
        \CommentTok{\# Actual trainable parameters}
        \ControlFlowTok{if}\NormalTok{ r }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
            \CommentTok{\# 参数矩阵 A}
            \VariableTok{self}\NormalTok{.lora\_A }\OperatorTok{=}\NormalTok{ nn.Linear(in\_features, r, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
            \CommentTok{\# 参数矩阵 B}
            \VariableTok{self}\NormalTok{.lora\_B }\OperatorTok{=}\NormalTok{ nn.Linear(r, out\_features, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
            \CommentTok{\# 归一化系数}
            \VariableTok{self}\NormalTok{.scaling }\OperatorTok{=} \VariableTok{self}\NormalTok{.lora\_alpha }\OperatorTok{/} \VariableTok{self}\NormalTok{.r}
            \CommentTok{\# 冻结原参数，仅更新 A 和 B}
            \VariableTok{self}\NormalTok{.weight.requires\_grad }\OperatorTok{=} \VariableTok{False}
        \CommentTok{\# 初始化 A 和 B}
        \VariableTok{self}\NormalTok{.reset\_parameters()}
        \ControlFlowTok{if}\NormalTok{ fan\_in\_fan\_out:}
            \VariableTok{self}\NormalTok{.weight.data }\OperatorTok{=} \VariableTok{self}\NormalTok{.weight.data.T}
\end{Highlighting}
\end{Shaded}

替换时，直接将原层的 weight 和 bias 复制给新的 LoRA 层，再将新的 LoRA
层分配到指定设备即可。

\paragraph{（4）训练}\label{ux8badux7ec3}

实现了 LoRA 层的替换后，进行微调训练即可。由于在 LoRA
层中已冻结原参数，在训练中只有 A 和 B
的参数会被更新，从而实现了高效微调。训练的整体过程与原 Fine-tune
类似，此处不再赘述。由于采用了 LoRA 方式，forward 函数也会对应调整：

\begin{Shaded}
\begin{Highlighting}[]
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x: torch.Tensor):}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.disable\_adapters:}
            \ControlFlowTok{if} \VariableTok{self}\NormalTok{.r }\OperatorTok{\textgreater{}} \DecValTok{0} \KeywordTok{and} \VariableTok{self}\NormalTok{.merged:}
                \VariableTok{self}\NormalTok{.weight.data }\OperatorTok{{-}=}\NormalTok{ (}
\NormalTok{                    transpose(}\VariableTok{self}\NormalTok{.lora\_B.weight }\OperatorTok{@} \VariableTok{self}\NormalTok{.lora\_A.weight, }\VariableTok{self}\NormalTok{.fan\_in\_fan\_out) }\OperatorTok{*} \VariableTok{self}\NormalTok{.scaling}
\NormalTok{                )}
                \VariableTok{self}\NormalTok{.merged }\OperatorTok{=} \VariableTok{False}

            \ControlFlowTok{return}\NormalTok{ F.linear(x, transpose(}\VariableTok{self}\NormalTok{.weight, }\VariableTok{self}\NormalTok{.fan\_in\_fan\_out), bias}\OperatorTok{=}\VariableTok{self}\NormalTok{.bias)}
        \CommentTok{\textquotesingle{}\textquotesingle{}\textquotesingle{}主要分支\textquotesingle{}\textquotesingle{}\textquotesingle{}}
        \ControlFlowTok{elif} \VariableTok{self}\NormalTok{.r }\OperatorTok{\textgreater{}} \DecValTok{0} \KeywordTok{and} \KeywordTok{not} \VariableTok{self}\NormalTok{.merged:}
\NormalTok{            result }\OperatorTok{=}\NormalTok{ F.linear(x, transpose(}\VariableTok{self}\NormalTok{.weight, }\VariableTok{self}\NormalTok{.fan\_in\_fan\_out), bias}\OperatorTok{=}\VariableTok{self}\NormalTok{.bias)}
            \ControlFlowTok{if} \VariableTok{self}\NormalTok{.r }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{                result }\OperatorTok{+=} \VariableTok{self}\NormalTok{.lora\_B(}\VariableTok{self}\NormalTok{.lora\_A(}\VariableTok{self}\NormalTok{.lora\_dropout(x))) }\OperatorTok{*} \VariableTok{self}\NormalTok{.scaling}
            \ControlFlowTok{return}\NormalTok{ result}
        \ControlFlowTok{else}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ F.linear(x, transpose(}\VariableTok{self}\NormalTok{.weight, }\VariableTok{self}\NormalTok{.fan\_in\_fan\_out), bias}\OperatorTok{=}\VariableTok{self}\NormalTok{.bias)}
\end{Highlighting}
\end{Shaded}

上述代码由于考虑到参数合并问题，有几个分支，此处我们仅阅读第二个分支即
elif 分支即可。基于 LoRA
的前向计算过程如前文公式所示，首先计算原参数与输入的乘积，再加上 A、B
分别与输入的乘积即可。

\subsubsection{6.3.5 使用 peft 实现 LoRA
微调}\label{ux4f7fux7528-peft-ux5b9eux73b0-lora-ux5faeux8c03}

peft
进行了很好的封装，支持我们便捷、高效地对大模型进行微调。此处以第二节的
LLM SFT 为例，简要介绍如何使用 peft 对大模型进行微调。如果是应用在 RLHF
上，整体思路是一致的。

首先加载所需使用库：

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch.nn }\ImportTok{as}\NormalTok{ nn}
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ AutoTokenizer, AutoModel}
\ImportTok{from}\NormalTok{ peft }\ImportTok{import}\NormalTok{ get\_peft\_model, LoraConfig, TaskType, PeftModel}
\ImportTok{from}\NormalTok{ transformers }\ImportTok{import}\NormalTok{ Trainer}
\end{Highlighting}
\end{Shaded}

其次加载原模型与原 tokenizer，此处和第二节一致：

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 加载基座模型}
\NormalTok{tokenizer }\OperatorTok{=}\NormalTok{ AutoTokenizer.from\_pretrained(MODEL\_PATH, trust\_remote\_code}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{model }\OperatorTok{=}\NormalTok{ AutoModel.from\_pretrained(}
\NormalTok{    MODEL\_PATH, trust\_remote\_code}\OperatorTok{=}\VariableTok{True}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

接着，设定 peft 参数：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{peft\_config }\OperatorTok{=}\NormalTok{ LoraConfig(}
\NormalTok{            task\_type}\OperatorTok{=}\NormalTok{TaskType.CAUSAL\_LM,}
\NormalTok{            inference\_mode}\OperatorTok{=}\VariableTok{False}\NormalTok{,}
\NormalTok{            r}\OperatorTok{=}\DecValTok{8}\NormalTok{,}
\NormalTok{            lora\_alpha}\OperatorTok{=}\DecValTok{32}\NormalTok{,}
\NormalTok{            lora\_dropout}\OperatorTok{=}\FloatTok{0.1}\NormalTok{,}
\NormalTok{        )}
\end{Highlighting}
\end{Shaded}

注意，对不同的模型，LoRA 参数可能有所区别。例如，对于 ChatGLM，无需指定
target\_modeules，peft 可以自行找到；对于
BaiChuan，就需要手动指定。task\_type 是模型的任务类型，大模型一般都是
CAUSAL\_LM 即传统语言模型。

然后获取 LoRA 模型：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model }\OperatorTok{=}\NormalTok{ get\_peft\_model(model, peft\_config)}
\end{Highlighting}
\end{Shaded}

此处的 get\_peft\_model 的底层操作，即为上文分析的具体实现。

最后使用 transformers 提供的 Trainer
进行训练即可，训练占用的显存就会有大幅度的降低：

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trainer }\OperatorTok{=}\NormalTok{ Trainer(}
\NormalTok{    model}\OperatorTok{=}\NormalTok{model,}
\NormalTok{    args}\OperatorTok{=}\NormalTok{training\_args,}
\NormalTok{    train\_dataset}\OperatorTok{=}\NormalTok{ IterableWrapper(train\_dataset),}
\NormalTok{    tokenizer}\OperatorTok{=}\NormalTok{tokenizer}
\NormalTok{)}
\NormalTok{trainer.train()}
\end{Highlighting}
\end{Shaded}

如果是应用在 DPO、KTO 上，则也相同的加入 LoRA 参数并通过
\texttt{get\_peft\_model} 获取一个 LoRA
模型即可，其他的不需要进行任何修改。但要注意的是，LoRA
微调能够大幅度降低显卡占用，且在下游任务适配上能够取得较好的效果，但如果是需要学习对应知识的任务，LoRA
由于只调整低秩矩阵，难以实现知识的注入，一般效果不佳，因此不推荐使用
LoRA 进行模型预训练或后训练。

\textbf{参考资料}

{[}1{]} Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna
Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and
Sylvain Gelly. (2019). \emph{Parameter-Efficient Transfer Learning for
NLP.} arXiv preprint arXiv:1902.00751.

{[}2{]} Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu,
Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. (2021). \emph{LoRA:
Low-Rank Adaptation of Large Language Models.} arXiv preprint
arXiv:2106.09685.

{[}3{]} Armen Aghajanyan, Luke Zettlemoyer, and Sonal Gupta. (2020).
\emph{Intrinsic Dimensionality Explains the Effectiveness of Language
Model Fine-Tuning.} arXiv preprint arXiv:2012.13255.

{[}4{]} Xiang Lisa Li 和 Percy Liang. (2021). \emph{Prefix-Tuning:
Optimizing Continuous Prompts for Generation.} arXiv preprint
arXiv:2101.00190.

\end{document}
