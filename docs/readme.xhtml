<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>Happy-LLM 项目简介</title>
  <link rel="stylesheet" type="text/css" href="./epub-style.css" />
</head>
<body>
  <div class="center">
    <img src="./images/head.jpg" alt="alt text" />
    <h1>Happy-LLM</h1>
  </div>
  <div class="center">
    <img src="https://img.shields.io/github/stars/datawhalechina/happy-llm?style=flat&amp;logo=github" alt="GitHub stars" />
    <img src="https://img.shields.io/github/forks/datawhalechina/happy-llm?style=flat&amp;logo=github" alt="GitHub forks" />
    <img src="https://img.shields.io/badge/language-Chinese-brightgreen?style=flat" alt="Language" />
    <a href="https://github.com/datawhalechina/happy-llm"><img src="https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;logo=github" alt="GitHub Project" /></a>
    <a href="https://swanlab.cn/@kmno4/Happy-LLM/overview"><img src="https://raw.githubusercontent.com/SwanHubX/assets/main/badge1.svg" alt="SwanLab" /></a>
  </div>
  <div class="center">
    <a href="https://trendshift.io/repositories/14175"><img src="https://trendshift.io/api/badge/repositories/14175" alt="datawhalechina%2Fhappy-llm | Trendshift" /></a>
  </div>
  <div class="center">
    <h3>📚 从零开始的大语言模型原理与实践教程</h3>
    <p><em>深入理解 LLM 核心原理，动手实现你的第一个大模型</em></p>
  </div>
  <div class="hr"></div>
  <div class="section">
    <h2>🎯 项目介绍</h2>
    <blockquote>
      很多小伙伴在看完 Datawhale开源项目： <a href="https://github.com/datawhalechina/self-llm">self-llm 开源大模型食用指南</a> 后，感觉意犹未尽，想要深入了解大语言模型的原理和训练过程。于是我们（Datawhale）决定推出《Happy-LLM》项目，旨在帮助大家深入理解大语言模型的原理和训练过程。
    </blockquote>
    <p>本项目是一个<strong>系统性的 LLM 学习教程</strong>，将从 NLP 的基本研究方法出发，根据 LLM 的思路及原理逐层深入，依次为读者剖析 LLM 的架构基础和训练过程。同时，我们会结合目前 LLM 领域最主流的代码框架，演练如何亲手搭建、训练一个 LLM，期以实现授之以鱼，更授之以渔。希望大家能从这本书开始走入 LLM 的浩瀚世界，探索 LLM 的无尽可能。</p>
  </div>
  <div class="section">
    <h2>✨ 你将收获什么？</h2>
    <ul>
      <li>📚 <strong>Datawhale 开源免费</strong> 完全免费的学习本项目所有内容</li>
      <li>🔍 <strong>深入理解</strong> Transformer 架构和注意力机制</li>
      <li>📚 <strong>掌握</strong> 预训练语言模型的基本原理</li>
      <li>🧠 <strong>了解</strong> 现有大模型的基本结构</li>
      <li>🏗️ <strong>动手实现</strong> 一个完整的 LLaMA2 模型</li>
      <li>⚙️ <strong>掌握训练</strong> 从预训练到微调的全流程</li>
      <li>🚀 <strong>实战应用</strong> RAG、Agent 等前沿技术</li>
    </ul>
  </div>
  <div class="section">
    <h2>📖 内容导航</h2>
    <table>
      <tr><th>章节</th><th>关键内容</th><th>状态</th></tr>
      <tr><td><a href="./前言.md">前言</a></td><td>本项目的缘起、背景及读者建议</td><td>✅</td></tr>
      <tr><td><a href="./chapter1/第一章%20NLP基础概念.md">第一章 NLP 基础概念</a></td><td>什么是 NLP、发展历程、任务分类、文本表示演进</td><td>✅</td></tr>
      <tr><td><a href="./chapter2/第二章%20Transformer架构.md">第二章 Transformer 架构</a></td><td>注意力机制、Encoder-Decoder、手把手搭建 Transformer</td><td>✅</td></tr>
      <tr><td><a href="./chapter3/第三章%20预训练语言模型.md">第三章 预训练语言模型</a></td><td>Encoder-only、Encoder-Decoder、Decoder-Only 模型对比</td><td>✅</td></tr>
      <tr><td><a href="./chapter4/第四章%20大语言模型.md">第四章 大语言模型</a></td><td>LLM 定义、训练策略、涌现能力分析</td><td>✅</td></tr>
      <tr><td><a href="./chapter5/第五章%20动手搭建大模型.md">第五章 动手搭建大模型</a></td><td>实现 LLaMA2、训练 Tokenizer、预训练小型 LLM</td><td>✅</td></tr>
      <tr><td><a href="./chapter6/第六章%20大模型训练流程实践.md">第六章 大模型训练实践</a></td><td>预训练、有监督微调、LoRA/QLoRA 高效微调</td><td>🚧</td></tr>
      <tr><td><a href="./chapter7/第七章%20大模型应用.md">第七章 大模型应用</a></td><td>模型评测、RAG 检索增强、Agent 智能体</td><td>✅</td></tr>
    </table>
  </div>
  <div class="section">
    <h2>模型下载</h2>
    <table>
      <tr><th>模型名称</th><th>下载地址</th></tr>
      <tr><td>Happy-LLM-Chapter5-Base-215M</td><td><a href="https://www.modelscope.cn/models/kmno4zx/happy-llm-215M-base">🤖 ModelScope</a></td></tr>
      <tr><td>Happy-LLM-Chapter5-SFT-215M</td><td><a href="https://www.modelscope.cn/models/kmno4zx/happy-llm-215M-sft">🤖 ModelScope</a></td></tr>
    </table>
    <p>ModelScope 创空间体验地址：<a href="https://www.modelscope.cn/studios/kmno4zx/happy_llm_215M_sft">🤖 创空间</a></p>
  </div>
  <div class="section">
    <h2>PDF 版本下载</h2>
    <p><strong>本 Happy-LLM PDF 教程完全开源免费。为防止各类营销号加水印后贩卖给大模型初学者，我们特地在 PDF 文件中预先添加了不影响阅读的 Datawhale 开源标志水印，敬请谅解～</strong></p>
    <ul>
      <li>Happy-LLM PDF : <a href="https://github.com/datawhalechina/happy-llm/releases/tag/PDF">https://github.com/datawhalechina/happy-llm/releases/tag/PDF</a></li>
      <li>Happy-LLM PDF 国内下载地址 : <a href="https://www.datawhale.cn/learn/summary/179">https://www.datawhale.cn/learn/summary/179</a></li>
    </ul>
  </div>
  <div class="section">
    <h2>💡 如何学习</h2>
    <p>本项目适合大学生、研究人员、LLM 爱好者。在学习本项目之前，建议具备一定的编程经验，尤其是要对 Python 编程语言有一定的了解。最好具备深度学习的相关知识，并了解 NLP 领域的相关概念和术语，以便更轻松地学习本项目。</p>
    <p>本项目分为两部分——基础知识与实战应用。第1章～第4章是基础知识部分，从浅入深介绍 LLM 的基本原理。其中，第1章简单介绍 NLP 的基本任务和发展，为非 NLP 领域研究者提供参考；第2章介绍 LLM 的基本架构——Transformer，包括原理介绍及代码实现，作为 LLM 最重要的理论基础；第3章整体介绍经典的 PLM，包括 Encoder-Only、Encoder-Decoder 和 Decoder-Only 三种架构，也同时介绍了当前一些主流 LLM 的架构和思想；第4章则正式进入 LLM 部分，详细介绍 LLM 的特点、能力和整体训练过程。第5章～第7章是实战应用部分，将逐步带领大家深入 LLM 的底层细节。其中，第5章将带领大家者基于 PyTorch 层亲手搭建一个 LLM，并实现预训练、有监督微调的全流程；第6章将引入目前业界主流的 LLM 训练框架 Transformers，带领学习者基于该框架快速、高效地实现 LLM 训练过程；第7章则将介绍 基于 LLM 的各种应用，补全学习者对 LLM 体系的认知，包括 LLM 的评测、检索增强生产（Retrieval-Augmented Generation，RAG）、智能体（Agent）的思想和简单实现。你可以根据个人兴趣和需求，选择性地阅读相关章节。</p>
    <p>在阅读本书的过程中，建议你将理论和实际相结合。LLM 是一个快速发展、注重实践的领域，我们建议你多投入实战，复现本书提供的各种代码，同时积极参加 LLM 相关的项目与比赛，真正投入到 LLM 开发的浪潮中。我们鼓励你关注 Datawhale 及其他 LLM 相关开源社区，当遇到问题时，你可以随时在本项目的 issue 区提问。</p>
    <p>最后，欢迎每一位读者在学习完本项目后加入到 LLM 开发者的行列。作为国内 AI 开源社区，我们希望充分聚集共创者，一起丰富这个开源 LLM 的世界，打造更多、更全面特色 LLM 的教程。星火点点，汇聚成海。我们希望成为 LLM 与普罗大众的阶梯，以自由、平等的开源精神，拥抱更恢弘而辽阔的 LLM 世界。</p>
  </div>
  <div class="section">
    <h2>🤝 如何贡献</h2>
    <ul>
      <li>🐛 <strong>报告 Bug</strong> - 发现问题请提交 Issue</li>
      <li>💡 <strong>功能建议</strong> - 有好想法就告诉我们</li>
      <li>📝 <strong>内容完善</strong> - 帮助改进教程内容 先提交一下, 再修改.</li>
      <li>🔧 <strong>代码优化</strong> - 提交 Pull Request</li>
    </ul>
  </div>
  <div class="section">
    <h2>🙏 致谢</h2>
    <h3>核心贡献者</h3>
    <ul>
      <li><a href="https://github.com/KMnO4-zx">宋志学-项目负责人</a> (Datawhale成员-中国矿业大学(北京))</li>
      <li><a href="https://github.com/logan-zou">邹雨衡-项目负责人</a> (Datawhale成员-对外经济贸易大学)</li>
      <li><a href="https://xinzhongzhu.github.io/">朱信忠-指导专家</a>（Datawhale首席科学家-浙江师范大学杭州人工智能研究院教授）</li>
    </ul>
    <h3>特别感谢</h3>
    <ul>
      <li>感谢 <a href="https://github.com/Sm1les">@Sm1les</a> 对本项目的帮助与支持</li>
      <li>感谢所有为本项目做出贡献的开发者们 ❤️</li>
    </ul>
    <div class="center">
      <a href="https://github.com/datawhalechina/happy-llm/graphs/contributors">
        <img src="https://contrib.rocks/image?repo=datawhalechina/happy-llm" alt="contributors" />
      </a>
    </div>
  </div>
  <div class="section">
    <h2>Star History</h2>
    <div class="center">
      <img src="./images/star-history-2025710.png" alt="Datawhale" />
    </div>
    <div class="center">
      <p>⭐ 如果这个项目对你有帮助，请给我们一个 Star！</p>
    </div>
  </div>
  <div class="section">
    <h2>关于 Datawhale</h2>
    <div class="center">
      <img src="./images/datawhale.png" alt="Datawhale" />
      <p>扫描二维码关注 Datawhale 公众号，获取更多优质开源内容</p>
    </div>
  </div>
  <div class="hr"></div>
  <div class="section">
    <h2>📜 开源协议</h2>
    <p>本作品采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可。</p>
  </div>
</body>
</html> 